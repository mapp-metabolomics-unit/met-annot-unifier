{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"met-annot-unifier","text":"<p>A Python project to combine tabular outputs from GNPS, Sirius and ISDB</p>"},{"location":"modules/","title":"Modules","text":""},{"location":"modules/#met_annot_unifier.cli.align_horizontally","title":"<code>align_horizontally(canopus_file, gnps_file, gnps_mn_file, isdb_file, sirius_file, output=None)</code>","text":"<p>CLI tool to align and merge data from CANOPUS, GNPS, Sirius, and ISDB horizontally.</p> <p>Parameters:</p> Name Type Description Default <code>canopus_file</code> <code>Optional[str]</code> <p>Path to CANOPUS output file.</p> required <code>gnps_file</code> <code>Optional[str]</code> <p>Path to GNPS output file.</p> required <code>gnps_mn_file</code> <code>Optional[str]</code> <p>Path to GNPS MN output file.</p> required <code>sirius_file</code> <code>Optional[str]</code> <p>Path to Sirius output file.</p> required <code>isdb_file</code> <code>Optional[str]</code> <p>Path to ISDB output file.</p> required <code>output</code> <code>Optional[str]</code> <p>Output file to save the merged data.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A dataframe with the aligned data (if the output option is used, the dataframe is saved to a file)</p> Source code in <code>met_annot_unifier/cli.py</code> <pre><code>@cli.command()\n@click.option(\"--canopus-file\", type=click.Path(), default=None, help=\"Path to CANOPUS output file.\")\n@click.option(\"--gnps-file\", type=click.Path(), default=None, help=\"Path to GNPS output file.\")\n@click.option(\"--gnps-mn-file\", type=click.Path(), default=None, help=\"Path to GNPS MN output file.\")\n@click.option(\"--isdb-file\", type=click.Path(), default=None, help=\"Path to ISDB output file.\")\n@click.option(\"--sirius-file\", type=click.Path(), default=None, help=\"Path to Sirius output file.\")\n@click.option(\"--output\", \"-o\", type=click.Path(), help=\"Output file to save the merged data.\")\ndef align_horizontally(\n    canopus_file: Optional[str],\n    gnps_file: Optional[str],\n    gnps_mn_file: Optional[str],\n    isdb_file: Optional[str],\n    sirius_file: Optional[str],\n    output: Optional[str] = None,\n) -&gt; None:\n    \"\"\"CLI tool to align and merge data from CANOPUS, GNPS, Sirius, and ISDB horizontally.\n\n    Args:\n        canopus_file (Optional[str]): Path to CANOPUS output file.\n        gnps_file (Optional[str]): Path to GNPS output file.\n        gnps_mn_file (Optional[str]): Path to GNPS MN output file.\n        sirius_file (Optional[str]): Path to Sirius output file.\n        isdb_file (Optional[str]): Path to ISDB output file.\n        output (Optional[str]): Output file to save the merged data.\n\n    Returns:\n        A dataframe with the aligned data (if the output option is used, the dataframe is saved to a file)\n    \"\"\"\n    aligned_data = align_data_horizontally(\n        canopus_file=canopus_file,\n        gnps_file=gnps_file,\n        gnps_mn_file=gnps_mn_file,\n        isdb_file=isdb_file,\n        sirius_file=sirius_file,\n    )\n\n    if output:\n        aligned_data.to_csv(output, index=False, sep=\"\\t\")\n        click.echo(f\"Aligned data saved to {output}\")\n    else:\n        click.echo(aligned_data)\n</code></pre>"},{"location":"modules/#met_annot_unifier.cli.align_vertically","title":"<code>align_vertically(gnps_file, sirius_file, isdb_file, output=None)</code>","text":"<p>CLI tool to align and merge data from GNPS, Sirius, and ISDB.</p> <p>Parameters:</p> Name Type Description Default <code>gnps_file</code> <code>str</code> <p>Path to GNPS output file.</p> required <code>isdb_file</code> <code>str</code> <p>Path to ISDB output file.</p> required <code>sirius_file</code> <code>str</code> <p>Path to Sirius output file.</p> required <code>output</code> <code>str</code> <p>Output file to save the merged data. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A dataframe with the aligned data (if the output option is used, the dataframe is saved to a file)</p> Source code in <code>met_annot_unifier/cli.py</code> <pre><code>@cli.command()\n@click.option(\"--gnps-file\", type=click.Path(exists=True), help=\"Path to GNPS output file.\")\n@click.option(\"--isdb-file\", type=click.Path(exists=True), help=\"Path to ISDB output file.\")\n@click.option(\"--sirius-file\", type=click.Path(exists=True), help=\"Path to Sirius output file.\")\n@click.option(\"--output\", \"-o\", type=click.Path(), help=\"Output file to save the merged data.\")\ndef align_vertically(gnps_file: str, sirius_file: str, isdb_file: str, output: Optional[str] = None) -&gt; None:\n    \"\"\"CLI tool to align and merge data from GNPS, Sirius, and ISDB.\n\n    Args:\n        gnps_file (str): Path to GNPS output file.\n        isdb_file (str): Path to ISDB output file.\n        sirius_file (str): Path to Sirius output file.\n        output (str, optional): Output file to save the merged data. Defaults to None.\n\n    Returns:\n        A dataframe with the aligned data (if the output option is used, the dataframe is saved to a file)\n    \"\"\"\n    aligned_data = align_data_vertically(gnps_file=gnps_file, isdb_file=isdb_file, sirius_file=sirius_file)\n\n    if output:\n        aligned_data.to_csv(output, index=False, sep=\"\\t\")\n        click.echo(f\"Aligned data saved to {output}\")\n    else:\n        click.echo(aligned_data)\n</code></pre>"},{"location":"modules/#met_annot_unifier.cli.cli","title":"<code>cli()</code>","text":"<p>Description for your CLI tool.</p> Source code in <code>met_annot_unifier/cli.py</code> <pre><code>@click.group()\ndef cli() -&gt; None:\n    \"\"\"Description for your CLI tool.\"\"\"\n    print(\"CLI is running\")\n    pass\n</code></pre>"},{"location":"modules/#met_annot_unifier.cli.prune_table","title":"<code>prune_table(input_file, list_columns, remove, output=None)</code>","text":"<p>CLI tool to remove columns from a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>input_file</code> <code>str</code> <p>Path to the input file.</p> required <code>list_columns</code> <code>str</code> <p>list of columns to remove.</p> required <code>remove</code> <code>bool</code> <p>If True, removes only the specified columns; otherwise, keeps them.</p> required <code>output</code> <code>str</code> <p>Output file to save the pruned data. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A dataframe with the pruned data (if the output option is used, the dataframe is saved to a file)</p> Source code in <code>met_annot_unifier/cli.py</code> <pre><code>@cli.command()\n@click.option(\"--input-file\", type=click.Path(exists=True), help=\"Path to the input file.\")\n@click.option(\"--remove\", is_flag=True, help=\"Removes the specified columns instead of keeping them.\")\n@click.option(\n    \"--list-columns\",\n    required=True,\n    help=\"Key in the JSON configuration for the list of columns to be processed.\",\n)\n@click.option(\"--output\", \"-o\", type=click.Path(), help=\"Output file to save the pruned data.\")\ndef prune_table(input_file: str, list_columns: str, remove: bool, output: Optional[str] = None) -&gt; None:\n    \"\"\"CLI tool to remove columns from a DataFrame.\n\n    Args:\n        input_file (str): Path to the input file.\n        list_columns (str): list of columns to remove.\n        remove (bool): If True, removes only the specified columns; otherwise, keeps them.\n        output (str, optional): Output file to save the pruned data. Defaults to None.\n\n    Returns:\n        A dataframe with the pruned data (if the output option is used, the dataframe is saved to a file)\n    \"\"\"\n\n    # Load the configuration file\n    columns_to_remove = load_configuration(\"column_config.json\")\n\n    # Get the columns to process\n    columns_to_process = columns_to_remove[list_columns]\n\n    # Load the input file\n    df = pd.read_csv(input_file, sep=\"\\t\")\n\n    # Prune the table\n    pruned_data = table_pruner(df, columns_to_process, remove=remove)\n\n    # Save or print the result\n    if output:\n        pruned_data.to_csv(output, index=False, sep=\"\\t\")\n        click.echo(f\"Pruned data saved to {output}\")\n    else:\n        click.echo(pruned_data.to_string())\n</code></pre>"},{"location":"modules/#met_annot_unifier.aligner.aligner.align_data_horizontally","title":"<code>align_data_horizontally(canopus_file=None, gnps_file=None, gnps_mn_file=None, isdb_file=None, sirius_file=None)</code>","text":"<p>Aligns and merges data from GNPS, Sirius, ISDB  and CANOPUS datasets, if provided. This function merges the data horizontally, keeping the data in a wide format. The function standardizes column names, prefixes them to indicate their source, and merges the data based on 'feature_id'.</p> <p>Args: canopus_file (Optional[str]): File path for the CANOPUS data in TSV format. gnps_file (Optional[str]): File path for the GNPS data in TSV format. isdb_file (Optional[str]): File path for the ISDB data in TSV format. sirius_file (Optional[str]): File path for the Sirius data in TSV format.</p> <p>Returns: pd.DataFrame: A DataFrame with aligned and merged data from the provided sources.</p> Source code in <code>met_annot_unifier/aligner/aligner.py</code> <pre><code>def align_data_horizontally(\n    canopus_file: Optional[str] = None,\n    gnps_file: Optional[str] = None,\n    gnps_mn_file: Optional[str] = None,\n    isdb_file: Optional[str] = None,\n    sirius_file: Optional[str] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Aligns and merges data from GNPS, Sirius, ISDB  and CANOPUS datasets, if provided. This function merges the data horizontally,\n    keeping the data in a wide format. The function standardizes column names, prefixes them to indicate their source,\n    and merges the data based on 'feature_id'.\n\n    Args:\n    canopus_file (Optional[str]): File path for the CANOPUS data in TSV format.\n    gnps_file (Optional[str]): File path for the GNPS data in TSV format.\n    isdb_file (Optional[str]): File path for the ISDB data in TSV format.\n    sirius_file (Optional[str]): File path for the Sirius data in TSV format.\n\n    Returns:\n    pd.DataFrame: A DataFrame with aligned and merged data from the provided sources.\n    \"\"\"\n\n    data_frames = []\n\n    if canopus_file:\n        canopus_data = pd.read_csv(canopus_file, sep=\"\\t\")\n        canopus_data = standardize_column_names(canopus_data, \"mappingFeatureId\", \"feature_id\")\n        canopus_data = prefix_columns(canopus_data, \"canopus_\", exclude_columns=[])\n        # the CANOPUS NPC classifier columns names are standardized\n        canopus_data = standardize_column_names(canopus_data, \"canopus_NPC#pathway\", \"canopus_npc_pathway\")\n        canopus_data = standardize_column_names(canopus_data, \"canopus_NPC#superclass\", \"canopus_npc_superclass\")\n        canopus_data = standardize_column_names(canopus_data, \"canopus_NPC#class\", \"canopus_npc_class\")\n        canopus_data = extract_feature_id(canopus_data, \"canopus_feature_id\")\n        canopus_data = standardize_column_names(canopus_data, \"canopus_feature_id\", \"feature_id\")\n        data_frames.append(canopus_data)\n\n    if gnps_file:\n        gnps_data = pd.read_csv(gnps_file, sep=\"\\t\")\n        gnps_data = standardize_column_names(gnps_data, \"InChIKey-Planar\", \"IK2D\")\n        gnps_data = standardize_column_names(gnps_data, \"#Scan#\", \"feature_id\")\n        gnps_data = standardize_column_names(gnps_data, \"Smiles\", \"SMILES\")\n        gnps_data = prefix_columns(gnps_data, \"gnps_\", exclude_columns=[])\n        # the GNPS NPC classifier columns names are standardized\n        gnps_data = standardize_column_names(gnps_data, \"gnps_npclassifier_pathway\", \"gnps_npc_pathway\")\n        gnps_data = standardize_column_names(gnps_data, \"gnps_npclassifier_superclass\", \"gnps_npc_superclass\")\n        gnps_data = standardize_column_names(gnps_data, \"gnps_npclassifier_class\", \"gnps_npc_class\")\n        gnps_data = standardize_column_names(gnps_data, \"gnps_feature_id\", \"feature_id\")\n        data_frames.append(gnps_data)\n\n    if isdb_file:\n        isdb_data = pd.read_csv(isdb_file, sep=\"\\t\")\n        isdb_data = standardize_column_names(isdb_data, \"short_inchikey\", \"IK2D\")\n        isdb_data = standardize_column_names(isdb_data, \"feature_id\", \"feature_id\")\n        isdb_data = standardize_column_names(isdb_data, \"structure_smiles\", \"SMILES\")\n        isdb_data = prefix_columns(isdb_data, \"isdb_\", exclude_columns=[])\n        # the ISDB NPC classifier columns names are standardized\n        isdb_data = standardize_column_names(\n            isdb_data, \"isdb_structure_taxonomy_npclassifier_01pathway\", \"isdb_npc_pathway\"\n        )\n        isdb_data = standardize_column_names(\n            isdb_data, \"isdb_structure_taxonomy_npclassifier_02superclass\", \"isdb_npc_superclass\"\n        )\n        isdb_data = standardize_column_names(\n            isdb_data, \"isdb_structure_taxonomy_npclassifier_03class\", \"isdb_npc_class\"\n        )\n        isdb_data = standardize_column_names(isdb_data, \"isdb_feature_id\", \"feature_id\")\n        data_frames.append(isdb_data)\n\n    if sirius_file:\n        # Read and process Sirius data\n        sirius_data = pd.read_csv(sirius_file, sep=\"\\t\")\n        sirius_data = standardize_column_names(sirius_data, \"InChIkey2D\", \"IK2D\")\n        sirius_data = standardize_column_names(sirius_data, \"mappingFeatureId\", \"feature_id\")\n        sirius_data = standardize_column_names(sirius_data, \"smiles\", \"SMILES\")\n        sirius_data = prefix_columns(sirius_data, \"sirius_\", exclude_columns=[])\n        sirius_data = extract_feature_id(sirius_data, \"sirius_feature_id\")\n        sirius_data = standardize_column_names(sirius_data, \"sirius_feature_id\", \"feature_id\")\n        data_frames.append(sirius_data)\n\n    if not data_frames:\n        raise DataFileError()\n\n    # Merge the dataframes horizontally on 'feature_id'\n    merged_data = reduce(lambda left, right: pd.merge(left, right, on=\"feature_id\", how=\"outer\"), data_frames)\n\n    # The sources of the annotations are processed and combined\n    # Create the 'Sources' column. Fill it according the content of the tool_IK2D columns.\n    # E.g. if sirius_IK2D is not null and matches isdb_IK2D, then the source is 'SIRIUS, ISDB'\n\n    merged_data = process_IK2D_sources(merged_data)\n    merged_data = process_npc_pathway_sources(merged_data)\n    merged_data = process_npc_superclass_sources(merged_data)\n    merged_data = process_npc_class_sources(merged_data)\n\n    merged_data[\"sources_number_IK2D\"] = merged_data[\"sources_IK2D\"].apply(count_sources)\n\n    # Load GNPS MN data if provided\n\n    if gnps_mn_file:\n        gnps_mn_data = pd.read_csv(gnps_mn_file, sep=\"\\t\")\n        gnps_mn_data = standardize_column_names(gnps_mn_data, \"cluster index\", \"feature_id\")\n        gnps_mn_data = prefix_columns(gnps_mn_data, \"gnps_mn_\", exclude_columns=[])\n        gnps_mn_data = standardize_column_names(gnps_mn_data, \"gnps_mn_feature_id\", \"feature_id\")\n        merged_data = pd.merge(merged_data, gnps_mn_data, on=\"feature_id\", how=\"outer\")\n\n    # Select columns\n\n    selected_columns = [\n        \"feature_id\",\n        \"sources_IK2D\",\n        \"sources_number_IK2D\",\n        \"sources_npc_pathway\",\n        \"sources_npc_superclass\",\n        \"sources_npc_class\",\n    ]\n\n    # Place the selected columns at the front of the dataframe\n\n    merged_data = merged_data[\n        selected_columns + [column for column in merged_data.columns if column not in selected_columns]\n    ]\n\n    return merged_data\n</code></pre>"},{"location":"modules/#met_annot_unifier.aligner.aligner.align_data_vertically","title":"<code>align_data_vertically(gnps_file=None, isdb_file=None, sirius_file=None)</code>","text":"<p>Aligns and merges data from GNPS, Sirius, and ISDB datasets optionally. Files can be provided for any subset of these datasets. The function standardizes column names, prefixes them to indicate their source, merges the data based on 'feature_id' and 'IK2D', and then creates consolidated 'Sources' and 'SMILES' columns.</p> <p>Parameters:</p> Name Type Description Default <code>gnps_file</code> <code>str</code> <p>File path for the GNPS data in TSV format.</p> <code>None</code> <code>sirius_file</code> <code>str</code> <p>File path for the Sirius data in TSV format.</p> <code>None</code> <code>isdb_file</code> <code>str</code> <p>File path for the ISDB data in TSV format.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame with aligned and merged data from the provided sources.</p> Example <p>gnps_file = 'path/to/gnps_data.tsv' sirius_file = 'path/to/sirius_data.tsv' aligned_data = align_data_vertically(gnps_file=gnps_file, sirius_file=sirius_file) print(aligned_data.columns) Index(['feature_id', 'IK2D', 'Sources', 'SMILES', ...], dtype='object')</p> Source code in <code>met_annot_unifier/aligner/aligner.py</code> <pre><code>def align_data_vertically(\n    gnps_file: Optional[str] = None,\n    isdb_file: Optional[str] = None,\n    sirius_file: Optional[str] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Aligns and merges data from GNPS, Sirius, and ISDB datasets optionally. Files can be provided for any subset of these datasets.\n    The function standardizes column names, prefixes them to indicate their source, merges the data based on 'feature_id'\n    and 'IK2D', and then creates consolidated 'Sources' and 'SMILES' columns.\n\n    Args:\n        gnps_file (str, optional): File path for the GNPS data in TSV format.\n        sirius_file (str, optional): File path for the Sirius data in TSV format.\n        isdb_file (str, optional): File path for the ISDB data in TSV format.\n\n    Returns:\n        pd.DataFrame: A DataFrame with aligned and merged data from the provided sources.\n\n    Example:\n        &gt;&gt;&gt; gnps_file = 'path/to/gnps_data.tsv'\n        &gt;&gt;&gt; sirius_file = 'path/to/sirius_data.tsv'\n        &gt;&gt;&gt; aligned_data = align_data_vertically(gnps_file=gnps_file, sirius_file=sirius_file)\n        &gt;&gt;&gt; print(aligned_data.columns)\n        Index(['feature_id', 'IK2D', 'Sources', 'SMILES', ...], dtype='object')\n    \"\"\"\n\n    data_frames = []\n\n    if gnps_file:\n        gnps_data = process_gnps_data(gnps_file)\n        data_frames.append(gnps_data)\n\n    if isdb_file:\n        isdb_data = process_isdb_data(isdb_file)\n        data_frames.append(isdb_data)\n\n    if sirius_file:\n        sirius_data = process_sirius_data(sirius_file)\n        data_frames.append(sirius_data)\n\n    # Ensure that at least one data frame has been loaded\n    if not data_frames:\n        raise DataFileError()\n\n    # Concatenate all available data frames\n    combined_data = pd.concat([df for df in data_frames if not df.empty], axis=0, ignore_index=True)\n    # Group by 'feature_id' and 'IK2D' and combine the annotations\n    merged_data = combined_data.groupby([\"feature_id\", \"IK2D\"], as_index=False).agg(\n        lambda x: \", \".join(x.dropna().astype(str).unique())\n    )\n\n    # Create the 'Sources' column\n    source_columns = [col for col in merged_data.columns if col.endswith(\"annotation_source\")]\n    merged_data[\"Sources\"] = merged_data.apply(\n        lambda row: \"|\".join(sorted(filter(None, [row.get(col) for col in source_columns]))), axis=1\n    )\n    merged_data.drop(columns=source_columns, inplace=True)\n\n    # Handle the SMILES column\n    # Specify the priority order for SMILES columns explicitly\n    smiles_columns = [\n        \"sirius_SMILES\",  # Highest priority\n        \"isdb_SMILES\",\n        \"gnps_SMILES\",  # Lowest priority\n    ]\n\n    # Check and keep only those columns that actually exist in the merged data\n    smiles_columns = [col for col in smiles_columns if col in merged_data.columns]\n    merged_data[\"SMILES\"] = merged_data.apply(\n        lambda row: next((row[col] for col in smiles_columns if row[col]), None), axis=1\n    )\n\n    # Select and reorder columns\n    selected_columns = [\"feature_id\", \"IK2D\", \"Sources\", \"SMILES\"]\n    merged_data = merged_data[selected_columns + [col for col in merged_data.columns if col not in selected_columns]]\n\n    return merged_data\n</code></pre>"}]}